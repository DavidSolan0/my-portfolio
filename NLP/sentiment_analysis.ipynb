{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db933b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dcbad",
   "metadata": {},
   "source": [
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3fdc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David.Solano\\Anaconda3\\envs\\David\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "import networkx as nx\n",
    "import re, unicodedata\n",
    "import dask.dataframe as ddf\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE\n",
    "from transformers import pipeline\n",
    "from prettytable import PrettyTable\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from gensim.models import CoherenceModel\n",
    "from networkx.algorithms import community\n",
    "from rpy2.robjects.packages import importr\n",
    "from gensim.utils import simple_preprocess\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "warnings.filterwarnings('ignore', 'SelectableGroups dict interface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5073147",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('input_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382b457",
   "metadata": {},
   "source": [
    "### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3601d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'col_name'\n",
    "project_name = 'project_name_'\n",
    "dataset_name = 'file_name.format'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d8ec1",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(dataset_name,engine ='openpyxl')\n",
    "\n",
    "nRow, nCol = df.shape\n",
    "df = df.set_index('Response ID')\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcdeb08",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### Stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53280ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words(\"spanish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784764e",
   "metadata": {},
   "source": [
    "#### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13208e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_lg')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def tokenizador(text):\n",
    "    return(' '.join(tknzr.tokenize(text)))\n",
    "\n",
    "def sent_to_words(sentence):\n",
    "    return(gensim.utils.simple_preprocess(str(sentence), deacc=True, min_len = 4))\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    return ' '.join([word.strip() for word in simple_preprocess(str(doc)) \n",
    "   if word.strip() not in stop_words])\n",
    "\n",
    "def lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV','INTJ']): \n",
    "    doc = nlp(text)\n",
    "    return  [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "\n",
    "def clean_text(df, variable = 'ABIERTA CON ORTOGRAFÍA'):\n",
    "    data_lemmatized = df[variable][~df[variable].isna()].map(tokenizador).map(sent_to_words).map(remove_stopwords).map(lemmatization)\n",
    "    \n",
    "    filtro = data_lemmatized.map(len) > 0 \n",
    "    data_lemmatized = data_lemmatized[filtro]\n",
    "    \n",
    "    return data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_lemmatized = clean_text(df,variable = col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac0ecf",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(chain.from_iterable(data_lemmatized))\n",
    "pt = PrettyTable(field_names=['Palabra', 'Conteo']) \n",
    "\n",
    "c = Counter(words)\n",
    "[ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "pt.align['Palabra'], pt.align['Conteo'] = 'l', 'r' \n",
    "pt._max_width = {'Palabra':60, 'Conteo':10}\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96acb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_words = ' '.join(words) \n",
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                min_font_size = 10).generate(str_words)\n",
    "                    \n",
    "plt.figure(figsize = (10,10), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a3a90",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc for doc in data_lemmatized.map(lambda x: ' '.join(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf54362",
   "metadata": {},
   "source": [
    "#### 5 stars review format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1f60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d2eeb4886a47c8b722734e078dc29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bdf4badc8e444caeb861a77dd21ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a244229c59584618b818dab5f6b300a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/838k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82edf8e176964604820c05f3f714ce17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92e630bc7ca4e82b462d76078766d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model)\n",
    "sentiment_clf = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "sentiment_clf('el servicio es increiblemente malo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_clf = generator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8ed24",
   "metadata": {},
   "source": [
    "#### Sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'pysentimiento/robertuito-sentiment-analysis'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model)\n",
    "sentiment_clf = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "sentiment_clf('el servicio es increiblemente malo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af24751",
   "metadata": {},
   "source": [
    "here if we obtaina score that allow us to predict a negative sentiment we could apply a hate speech classificator with the following classes\n",
    "\n",
    "* HS: is it hate speech?\n",
    "* TR: is it targeted to a specific individual?\n",
    "* AG: is it aggressive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366239fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'pysentimiento/robertuito-hate-speech'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model)\n",
    "sentiment_clf = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "sentiment_clf('el servicio es increiblemente malo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434ce29",
   "metadata": {},
   "source": [
    "#### Emotion classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6859d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'pysentimiento/robertuito-emotion-analysis'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model)\n",
    "sentiment_clf = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "sentiment_clf('el servicio es increiblemente malo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
